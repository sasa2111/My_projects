
Задача предсказания ценовой категории актомобиля по его параметрам.

Jupyter notebook:
В файле описан полный процесс обработки датасета vehicles_dataset.csv (в папке data) и обучения трех разных моделей для предсказания ценовой категории автомобиля, 
оценки их эффективности, выбора лучшей.
В датасете - информация о 10 тыс объявлений о продаже автомобилей в США.

Описание датасета:
id: идентификатор записи;
url: URL записи о продаже;
region: регион;
region_url: URL региона;
price: стоимость;
year: год выпуска;
manufacturer: производитель;
model: модель;
condition: состояние;
cylinders: количество цилиндров;
fuel: тип топлива;
odometer: количество пройденных миль;
title_status: статус;
transmission: коробка передач;
VIN: идентификационный номер;
drive: тип привода;
size: размер;
type: кузов;
paint_color: цвет;
image_url: URL изображения;
description: указанное описание;
county: страна;
state: штат;
lat: широта;
long: долгота;
posting_date: дата размещения объявления о продаже;
price_category: категория цены.

Целевая переменная price_category.

Задачи:
  - изучить датафрейм
  - почистить, привести типы, заполнить пропуски данных, где возможно.
  - проверить выбросы в данных, возможно сделать корректировки с учетом выбросов
  - визуализировать данные, посмотреть на графики, предположить закономерности
  - сгенерировать дополнительные фичи (создать в принципе новые фичи, отнормировать имеющиеся числовые, из категориальных создать новые с помощью OnehotEncoder)
  - обучить 3 модели:
    -- логистическая регрессия
    -- многослойный персептрон
    -- случайный лес
  - провести кросс-валидацию и сравнить результаты моделей, выбрать лучшую, Обучить ее на полном датасете, сохранить в файл pickle.

Этапы работы с датасетом:

1. Data Understanding 
  - верхнеуровневое изучение
2. Data Preparation: EDA (explorary data analysis)
  - Исследование переменных датасета
  - Data Cleaning: дубли, пропуски в данных, приведение типов данных, аномации и выбросы
  - Data Visualization
  - Feature Engineering
3. Modeling
  - логистическая регрессия (с параметрами по умолч. + тюнинг модели)
  - многослойный персептрон (с параметрами по умолч. + тюнинг модели)
  - случайный лес (с параметрами по умолч. + тюнинг модели)
4. Evaluation
  - кросс-валидация моделей
  - выбор лучшей модели
  - обучение лучшей модели на полном датасете и сохранение ее в файл pkl
  
Комментарии:
В файле jupyter notebook описан весь исследовательский процесс работы с датасетом, 
который в дальнейшем может быть использован для создания пайплайна или дага в airflow - в сокращенном виде, с учетом полученных результатов.

Ноутбук разбит на главы и подглавы, соответствующие этапам работы с данными: 
изучения, преобразования датасета, моделирования, тюнинга моделей, оценки их качества и выбора лучше.

Изучать программу удобнее в jupyter lab или colab - там сразу видно структуру, удобная навигация по главам.

Полученные результаты по итогам моделирования:
Наилучшую точность прогнозирования ценовой категории показал случайный лес по итогам кросс-валидации.


  
  
  




